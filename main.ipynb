{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0a7122",
   "metadata": {},
   "source": [
    "**Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import easyocr\n",
    "import cv2\n",
    "from rapidfuzz import fuzz\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e128b1c",
   "metadata": {},
   "source": [
    "**Gemini Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d788c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, image_path) -> list | dict:\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.5-flash\",\n",
    "        system_instruction=\"You are a helpful assistant that extracts newspaper fields from images.\",\n",
    "        generation_config={\"response_mime_type\": \"application/json\"}\n",
    "    )\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "\n",
    "    response = model.generate_content([\n",
    "        {\"text\": prompt},\n",
    "        {\"mime_type\": \"image/png\", \"data\": image_bytes}\n",
    "    ])\n",
    "\n",
    "    raw_json = response.text\n",
    "    data = json.loads(raw_json)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4b3f9",
   "metadata": {},
   "source": [
    "**Call to generate headline from Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ad9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_schema = {\n",
    "\t\"type\": \"array\",\n",
    "\t\"items\": {\"type\": \"string\"}\n",
    "}\n",
    "\n",
    "headline_prompt = (\n",
    "\t\"You are given a newspaper image. \"\n",
    "\t\"Extract only the article all possible headlines — ignore advertisements, captions, subheadlines, and any other text. \"\n",
    "\t\"Return the result strictly matching this JSON schema:\\n\\n\"\n",
    "\tf\"{json.dumps(headline_schema, indent=2)}\"\n",
    ")\n",
    "\n",
    "target_image_path = \"page_1.png\"\n",
    "\n",
    "generated_headlines = generate(headline_prompt, \"input/\" + target_image_path)\n",
    "\n",
    "# Dev log\n",
    "print(json.dumps(generated_headlines, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61716e67",
   "metadata": {},
   "source": [
    "**EasyOCR reads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d15d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])\n",
    "image = cv2.imread(\"input/\" + target_image_path)\n",
    "results = reader.readtext(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754fbe9",
   "metadata": {},
   "source": [
    "**Shows how the OCR reads the newspaper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_raw = image.copy()\n",
    "for (top_left, top_right, bottom_right, bottom_left), text, confidence in results:\n",
    "    tl = (int(top_left[0]), int(top_left[1]))\n",
    "    br = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "    cv2.rectangle(image_raw, tl, br, (0, 255, 0), 2)\n",
    "\n",
    "    coord_label = f\"{tl} {br}\"  \n",
    "    cv2.putText(image_raw, text, (tl[0], tl[1] - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "output_path_raw = \"ocr_reads/\" + target_image_path\n",
    "cv2.imwrite(output_path_raw, image_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e17bb",
   "metadata": {},
   "source": [
    "**Filter out text that matches with the list of headlines from Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a24a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_texts_by_score(texts: list, threshold: int = 70) -> list:\n",
    "\n",
    "    possible_texts = {}\n",
    "    for text in texts:\n",
    "        if text and text in possible_texts:\n",
    "            text += \".\"\n",
    "        if text:\n",
    "            possible_texts[text] = {\n",
    "                \"texts\": [],\n",
    "                \"boxes\": []\n",
    "            }\n",
    "\n",
    "    for coordinates, text, _ in results:\n",
    "        \n",
    "        for headline in possible_texts:\n",
    "            score = fuzz.partial_ratio(headline, text)\n",
    "            if score > threshold:\n",
    "                top_left, _, bottom_right, _ = coordinates\n",
    "                \n",
    "                current_box = ((int(top_left[0]), int(top_left[1])),\n",
    "                            (int(bottom_right[0]), int(bottom_right[1])))\n",
    "                possible_texts[headline][\"texts\"].append(text)\n",
    "                possible_texts[headline][\"boxes\"].append(current_box)\n",
    "    print(possible_texts)\n",
    "    return possible_texts\n",
    "        \n",
    "possible_headlines = filter_texts_by_score(generated_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6194ee",
   "metadata": {},
   "source": [
    "**Merging Bounding boxes that are close to each other**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_bounding_boxes(texts: list) -> list:\n",
    "\n",
    "    def is_close(coordinate1, coordinate2, gap_x=30, gap_y=20):\n",
    "        (x1_min, y1_min), (x1_max, y1_max) = coordinate1\n",
    "        (x2_min, y2_min), (x2_max, y2_max) = coordinate2\n",
    "\n",
    "        # Overlaps\n",
    "        overlap_x = min(x1_max, x2_max) - max(x1_min, x2_min)\n",
    "        overlap_y = min(y1_max, y2_max) - max(y1_min, y2_min)\n",
    "\n",
    "        # Edge alignment (corner-based)\n",
    "        align_x = (abs(x1_min - x2_min) <= gap_x) or (abs(x1_max - x2_max) <= gap_x)\n",
    "        align_y = (abs(y1_min - y2_min) <= gap_y) or (abs(y1_max - y2_max) <= gap_y)\n",
    "\n",
    "        # If boxes intersect at all, they’re close\n",
    "        if overlap_x > 0 and overlap_y > 0:\n",
    "            return True\n",
    "\n",
    "        # Side-by-side: small gap on X AND top/bottom edges align (corner closeness)\n",
    "        side_by_side = (\n",
    "            (0 <= x2_min - x1_max <= gap_x) or\n",
    "            (0 <= x1_min - x2_max <= gap_x)\n",
    "        ) and align_y\n",
    "\n",
    "        # Stacked: small gap on Y AND left/right edges align (corner closeness)\n",
    "        stacked = (\n",
    "            (0 <= y2_min - y1_max <= gap_y) or\n",
    "            (0 <= y1_min - y2_max <= gap_y)\n",
    "        ) and align_x\n",
    "\n",
    "        return side_by_side or stacked\n",
    "\n",
    "    # value is list of dicts with \"text\" and \"box\"\n",
    "    new = {}\n",
    "\n",
    "    for headline, obj in texts.items():\n",
    "\n",
    "        new[headline] = []\n",
    "\n",
    "        for i in range(len(obj[\"texts\"])):\n",
    "            text = obj[\"texts\"][i]\n",
    "            box = obj[\"boxes\"][i]\n",
    "\n",
    "            if not new[headline]:\n",
    "                new[headline].append({\"text\": text, \"box\": box})\n",
    "\n",
    "            else:\n",
    "                for i, currentBox in enumerate(new[headline]):\n",
    "                    if headline == \"By Pot Chavez and Vince Lopez\":\n",
    "                        \n",
    "                        print(text)\n",
    "                        print(\"result\", is_close(currentBox[\"box\"], box))\n",
    "                        print(box, currentBox[\"box\"])\n",
    "                    if is_close(currentBox[\"box\"], box):\n",
    "                        (ex_tl_x, ex_tl_y), (ex_br_x, ex_br_y) = currentBox[\"box\"]\n",
    "                        (tl_x, tl_y), (br_x, br_y) = box\n",
    "\n",
    "                        new_tl = (min(ex_tl_x, tl_x), min(ex_tl_y, tl_y))\n",
    "                        new_br = (max(ex_br_x, br_x), max(ex_br_y, br_y))\n",
    "\n",
    "                        new[headline][i][\"box\"] = (new_tl, new_br)\n",
    "                        new[headline][i][\"text\"] += \" \" + text\n",
    "                        break\n",
    "                else:\n",
    "                    new[headline].append({\"text\": text, \"box\": box})\n",
    "\n",
    "    for key in new:\n",
    "        for i in range(len(new[key])):\n",
    "            for j in range(i + 1, len(new[key])):\n",
    "                if is_close(new[key][i][\"box\"], new[key][j][\"box\"]):\n",
    "                    (ex_tl_x, ex_tl_y), (ex_br_x, ex_br_y) = new[key][i][\"box\"]\n",
    "                    (tl_x, tl_y), (br_x, br_y) = new[key][j][\"box\"]\n",
    "\n",
    "                    new_tl = (min(ex_tl_x, tl_x), min(ex_tl_y, tl_y))\n",
    "                    new_br = (max(ex_br_x, br_x), max(ex_br_y, br_y))\n",
    "\n",
    "                    new[key][i][\"box\"] = (new_tl, new_br)\n",
    "                    new[key][i][\"text\"] += \" \" + new[key][j][\"text\"]\n",
    "                    del new[key][j]\n",
    "                    break \n",
    "    print(json.dumps(new, indent=2))\n",
    "    return new\n",
    "\n",
    "merged_texts_headlines = merging_bounding_boxes(possible_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ec732",
   "metadata": {},
   "source": [
    "**Call again to Gemini for the others parts of the article based on the generated headline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"headline\": {\"type\": \"string\"},\n",
    "            \"subheadline\": {\"type\": \"string\"},\n",
    "            \"body\" : {\"type\": \"string\"},\n",
    "            \"byline\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"subheadline\", \"body\", \"byline\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "article_prompt = (\n",
    "\t\"You are given a newspaper image. \"\n",
    "\t\"From the given headlines, extract their subheadline if there is any (required: subheadlines must have higher font size compared to body)\"\n",
    "\t\"From the given headlines, extract their body\"\n",
    "\t\"Also extract the article's byline or author from the given headlines — bylines might appear after your generated body and will never appear on top of the headline\"\n",
    "    \"use the following headlines to find the subheadline, body and bylines: \"\n",
    "    f\"{json.dumps(generated_headlines, indent=2)}. \"\n",
    "\t\"Return the result strictly matching this JSON schema:\\n\\n\"\n",
    "\tf\"{json.dumps(article_schema, indent=2)}\"\n",
    ")\n",
    "\n",
    "generated_article = generate(article_prompt, \"input/\" + target_image_path)\n",
    "\n",
    "def transform_articles(articles):\n",
    "    transformed = []\n",
    "    for article in articles:\n",
    "        new_article = {}\n",
    "        for key, value in article.items():\n",
    "            new_article[key] = {\n",
    "                \"text\": value,\n",
    "                \"coordinate\": []\n",
    "            }\n",
    "        transformed.append(new_article)\n",
    "    return transformed\n",
    "\n",
    "return_json = transform_articles(generated_article)\n",
    "print(return_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f84b7",
   "metadata": {},
   "source": [
    "**Picks the Best match and write their bounding box**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf860f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_image = image.copy()\n",
    "\n",
    "def boxes_overlap(box1, box2):\n",
    "    (x1_min, y1_min), (x1_max, y1_max) = box1\n",
    "    (x2_min, y2_min), (x2_max, y2_max) = box2\n",
    "\n",
    "    # check if boxes intersect\n",
    "    return not (x1_max < x2_min or x2_max < x1_min or\n",
    "                y1_max < y2_min or y2_max < y1_min)\n",
    "\n",
    "\n",
    "\n",
    "def match_score(query, candidate):\n",
    "    # 1. partial ratio (substring match)\n",
    "    partial = fuzz.partial_ratio(query, candidate)\n",
    "    # 2. full ratio (length + overall match)\n",
    "    full = fuzz.ratio(query, candidate)\n",
    "    # 3. token set (ignores word order & duplicates)\n",
    "    token = fuzz.token_set_ratio(query, candidate)\n",
    "\n",
    "    # weighted average (tweak weights as needed)\n",
    "    score = (partial * 0.4) + (full * 0.3) + (token * 0.3)\n",
    "    return score\n",
    "\n",
    "\n",
    "def draw_boxes(texts: list, color=(0, 255, 0), thickness=5, part=\"headline\"):\n",
    "    drawn_boxes = []  # store drawn rectangles as (tl, br)\n",
    "    \n",
    "    for i, key in enumerate(texts):\n",
    "        query = key\n",
    "        choices = []\n",
    "        cord = []\n",
    "        for obj in texts[key]:\n",
    "            if drawn_boxes:\n",
    "                if obj[\"box\"] in drawn_boxes:\n",
    "                    continue\n",
    "                else:\n",
    "                    choices.append(obj[\"text\"])\n",
    "                    cord.append(obj[\"box\"])\n",
    "            else:\n",
    "                choices.append(obj[\"text\"])\n",
    "                cord.append(obj[\"box\"])\n",
    "\n",
    "\n",
    "        if not choices:\n",
    "            continue  # skip if no choices\n",
    "\n",
    "        # map choice → index\n",
    "        choices_dict = {c: i for i, c in enumerate(choices)}\n",
    "\n",
    "        # get best match\n",
    "        best_match = process.extractOne(query, list(choices_dict.keys()))\n",
    "\n",
    "        if best_match:\n",
    "            text, _ = best_match\n",
    "            tl, br = cord[choices.index(text)]\n",
    "            new_box = (tl, br)\n",
    "                   \n",
    "            # skip if overlaps any existing box\n",
    "            if any(boxes_overlap(new_box, old) for old in drawn_boxes):\n",
    "                continue\n",
    "            # draw box\n",
    "            cv2.rectangle(result_image, tl, br, color, thickness)\n",
    "\n",
    "            print(\"result =\", text, (tl, br))\n",
    "            drawn_boxes.append((tl, br))\n",
    "            \n",
    "            if part != \"headline\":\n",
    "                for index, obj in enumerate(return_json):\n",
    "                    print(index, obj)\n",
    "                    obj[part][\"text\"]\n",
    "                    score = match_score(obj[part][\"text\"], text)\n",
    "                    if score > 90:\n",
    "                        i = index\n",
    "                        print(\"success\")\n",
    "                        return_json[i][part][\"coordinate\"] = [*tl, *br]\n",
    "            else:\n",
    "                return_json[i][part][\"coordinate\"] = [*tl, *br]\n",
    "\n",
    "\n",
    "    # save output\n",
    "    cv2.imwrite(\"output/\" + target_image_path, result_image)\n",
    "\n",
    "draw_boxes(merged_texts_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508c105",
   "metadata": {},
   "source": [
    "**Run the rest parts of the article**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bylines = [i[\"byline\"] for i in generated_article]\n",
    "possible_bylines = filter_texts_by_score(bylines)\n",
    "merged_bylines = merging_bounding_boxes(possible_bylines)\n",
    "draw_boxes(merged_bylines, color=(0, 0, 255), part=\"byline\")\n",
    "\n",
    "subheadlines = [i[\"subheadline\"] for i in generated_article]\n",
    "possible_subheadlines = filter_texts_by_score(subheadlines)\n",
    "merged_subheadlines = merging_bounding_boxes(possible_subheadlines)\n",
    "draw_boxes(merged_subheadlines, color=(255, 0, 0), part=\"subheadline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855f959",
   "metadata": {},
   "source": [
    "**Save the details as JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0597aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"json/{target_image_path.split('.')[0] + '.json'}\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(return_json, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
