{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0a7122",
   "metadata": {},
   "source": [
    "**Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import easyocr\n",
    "import cv2\n",
    "from rapidfuzz import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e128b1c",
   "metadata": {},
   "source": [
    "**Gemini Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d788c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, image_path) -> list | dict:\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.5-flash\",\n",
    "        system_instruction=\"You are a helpful assistant that extracts newspaper fields from images.\",\n",
    "        generation_config={\"response_mime_type\": \"application/json\"}\n",
    "    )\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "\n",
    "    response = model.generate_content([\n",
    "        {\"text\": prompt},\n",
    "        {\"mime_type\": \"image/png\", \"data\": image_bytes}\n",
    "    ])\n",
    "\n",
    "    raw_json = response.text\n",
    "    data = json.loads(raw_json)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4b3f9",
   "metadata": {},
   "source": [
    "**Call to generate headline from Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ad9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_schema = {\n",
    "\t\"type\": \"array\",\n",
    "\t\"items\": {\"type\": \"string\"}\n",
    "}\n",
    "\n",
    "headline_prompt = (\n",
    "\t\"You are given a newspaper image. \"\n",
    "\t\"Extract only the article all possible headlines — ignore advertisements, captions, subheadlines, and any other text. \"\n",
    "\t\"Return the result strictly matching this JSON schema:\\n\\n\"\n",
    "\tf\"{json.dumps(headline_schema, indent=2)}\"\n",
    ")\n",
    "\n",
    "target_image_path = \"page_17.png\"\n",
    "\n",
    "headlines = generate(headline_prompt, target_image_path)\n",
    "\n",
    "for i, headline in enumerate(headlines):\n",
    "    headlines[i] = headline\n",
    "\n",
    "# Dev log\n",
    "print(json.dumps(headlines, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61716e67",
   "metadata": {},
   "source": [
    "**EasyOCR reads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d15d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])\n",
    "image = cv2.imread(target_image_path)\n",
    "results = reader.readtext(image)\n",
    "\n",
    "image_raw = image.copy()\n",
    "for (top_left, top_right, bottom_right, bottom_left), text, confidence in results:\n",
    "    tl = (int(top_left[0]), int(top_left[1]))\n",
    "    br = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "    cv2.rectangle(image_raw, tl, br, (0, 0, 255), 2)\n",
    "    coord_label = f\"{tl} {br}\"  \n",
    "    cv2.putText(image_raw, coord_label, (tl[0], tl[1] - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "output_path_raw = target_image_path.replace(\".png\", \"_ocr_boxes.png\")\n",
    "cv2.imwrite(output_path_raw, image_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e17bb",
   "metadata": {},
   "source": [
    "**Filter out text that matches with the list of headlines from Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a24a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_headlines = {}\n",
    "for headline in headlines:\n",
    "    possible_headlines[headline] = {\n",
    "        \"texts\": [],\n",
    "        \"boxes\": []\n",
    "    }\n",
    "\n",
    "for coordinates, text, _ in results:\n",
    "    \n",
    "    for headline in possible_headlines:\n",
    "        score = fuzz.partial_ratio(headline, text)\n",
    "        if score > 80:\n",
    "            top_left, _, bottom_right, _ = coordinates\n",
    "            \n",
    "            current_box = ((int(top_left[0]), int(top_left[1])),\n",
    "                           (int(bottom_right[0]), int(bottom_right[1])))\n",
    "            possible_headlines[headline][\"texts\"].append(text)\n",
    "            possible_headlines[headline][\"boxes\"].append(current_box)\n",
    "\n",
    "print(json.dumps(possible_headlines, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6194ee",
   "metadata": {},
   "source": [
    "**Merging Bounding boxes that are close to each other**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_close(coordinate1, coordinate2, gap_x=30, gap_y=20):\n",
    "    (x1_min, y1_min), (x1_max, y1_max) = coordinate1\n",
    "    (x2_min, y2_min), (x2_max, y2_max) = coordinate2\n",
    "\n",
    "    # Overlaps\n",
    "    overlap_x = min(x1_max, x2_max) - max(x1_min, x2_min)\n",
    "    overlap_y = min(y1_max, y2_max) - max(y1_min, y2_min)\n",
    "\n",
    "    # Edge alignment (corner-based)\n",
    "    align_x = (abs(x1_min - x2_min) <= gap_x) or (abs(x1_max - x2_max) <= gap_x)\n",
    "    align_y = (abs(y1_min - y2_min) <= gap_y) or (abs(y1_max - y2_max) <= gap_y)\n",
    "\n",
    "    # If boxes intersect at all, they’re close\n",
    "    if overlap_x > 0 and overlap_y > 0:\n",
    "        return True\n",
    "\n",
    "    # Side-by-side: small gap on X AND top/bottom edges align (corner closeness)\n",
    "    side_by_side = (\n",
    "        (0 <= x2_min - x1_max <= gap_x) or\n",
    "        (0 <= x1_min - x2_max <= gap_x)\n",
    "    ) and align_y\n",
    "\n",
    "    # Stacked: small gap on Y AND left/right edges align (corner closeness)\n",
    "    stacked = (\n",
    "        (0 <= y2_min - y1_max <= gap_y) or\n",
    "        (0 <= y1_min - y2_max <= gap_y)\n",
    "    ) and align_x\n",
    "\n",
    "    return side_by_side or stacked\n",
    "\n",
    "# value is list of dicts with \"text\" and \"box\"\n",
    "new = {}\n",
    "\n",
    "for headline, obj in possible_headlines.items():\n",
    "\n",
    "    new[headline] = []\n",
    "\n",
    "    for i in range(len(obj[\"texts\"])):\n",
    "        text = obj[\"texts\"][i]\n",
    "        box = obj[\"boxes\"][i]\n",
    "\n",
    "        if not new[headline]:\n",
    "            new[headline].append({\"text\": text, \"box\": box})\n",
    "\n",
    "        else:\n",
    "            for i, currentBox in enumerate(new[headline]):\n",
    "                score = fuzz.ratio(new[headline][i][\"text\"], headline)\n",
    "                \n",
    "                if score >= 90:\n",
    "                    break\n",
    "                if is_close(currentBox[\"box\"], box):\n",
    "                    \n",
    "                    (ex_tl_x, ex_tl_y), (ex_br_x, ex_br_y) = currentBox[\"box\"]\n",
    "                    (tl_x, tl_y), (br_x, br_y) = box\n",
    "\n",
    "                    new_tl = (min(ex_tl_x, tl_x), min(ex_tl_y, tl_y))\n",
    "                    new_br = (max(ex_br_x, br_x), max(ex_br_y, br_y))\n",
    "\n",
    "                    new[headline][i][\"box\"] = (new_tl, new_br)\n",
    "                    new[headline][i][\"text\"] += \" \" + text\n",
    "                    break\n",
    "            else:\n",
    "                new[headline].append({\"text\": text, \"box\": box})\n",
    "\n",
    "for key in new:\n",
    "    print(new[key])\n",
    "    for i in range(len(new[key])):\n",
    "        for j in range(i + 1, len(new[key])):\n",
    "            if is_close(new[key][i][\"box\"], new[key][j][\"box\"]):\n",
    "                print(f\"Merging {new[key][i]} and {new[key][j]}\")\n",
    "                (ex_tl_x, ex_tl_y), (ex_br_x, ex_br_y) = new[key][i][\"box\"]\n",
    "                (tl_x, tl_y), (br_x, br_y) = new[key][j][\"box\"]\n",
    "\n",
    "                new_tl = (min(ex_tl_x, tl_x), min(ex_tl_y, tl_y))\n",
    "                new_br = (max(ex_br_x, br_x), max(ex_br_y, br_y))\n",
    "\n",
    "                new[key][i][\"box\"] = (new_tl, new_br)\n",
    "                new[key][i][\"text\"] += \" \" + new[key][j][\"text\"]\n",
    "                del new[key][j]\n",
    "                break\n",
    "\n",
    "print(json.dumps(new, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f84b7",
   "metadata": {},
   "source": [
    "**Picks the Best match and write their bounding box**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf860f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_merged = image.copy()\n",
    "\n",
    "for key in new:\n",
    "    query = key\n",
    "    choices = [i[\"text\"] for i in new[key]]\n",
    "\n",
    "    if not choices:\n",
    "        continue  # skip if no choices\n",
    "\n",
    "    # map choice → index\n",
    "    choices_dict = {c: i for i, c in enumerate(choices)}\n",
    "\n",
    "    # get best match\n",
    "    best_match = process.extractOne(query, list(choices_dict.keys()))\n",
    "    if best_match:\n",
    "        text, score = best_match\n",
    "        index = choices_dict[text]\n",
    "        tl, br = new[key][index][\"box\"]\n",
    "        print(f\"{text=} {tl=} {br=}\")\n",
    "        cv2.rectangle(image_merged, tl, br, (0, 255, 0), 5)\n",
    "\n",
    "# save output\n",
    "output_path_merged = f\"{os.path.splitext(target_image_path)[0]}_result{os.path.splitext(target_image_path)[1]}\"\n",
    "cv2.imwrite(output_path_merged, image_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508c105",
   "metadata": {},
   "source": [
    "**Generate Byline from Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84497647",
   "metadata": {},
   "outputs": [],
   "source": [
    "byline_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"headline\": {\"type\": \"string\"},\n",
    "            \"byline\": {\"type\": \"string\"},\n",
    "        },\n",
    "        \"required\": [\"headline\", \"byline\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "byline_prompt = (\n",
    "\t\"You are given a newspaper image. \"\n",
    "\t\"Extract only the article's byline or author from the given headlines — ignore advertisements, captions, subheadlines, and any other text. \"\n",
    "    \"use the following headlines to find the bylines: \"\n",
    "    f\"{json.dumps(headlines, indent=2)}. \"\n",
    "\t\"Return the result strictly matching this JSON schema:\\n\\n\"\n",
    "\tf\"{json.dumps(byline_schema, indent=2)}\"\n",
    ")\n",
    "\n",
    "bylines = generate(byline_prompt, target_image_path)\n",
    "\n",
    "print(json.dumps(bylines, indent=2, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
